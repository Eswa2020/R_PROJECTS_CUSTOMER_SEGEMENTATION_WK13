---
title: "Advertising _&_Marketing_Proposal_For_Kiraplastinina"
author: "Esther_Wairimu_Kamau"
date: "1/16/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1.Problem Statement
Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in
Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia.

The brand’s Sales and Marketing team would like to understand their customer’s behavior
from data that they have collected over the past year.

More specifically, they would like to learn the characteristics of customer groups.
We will perform clustering stating insights drawn from our analysis and visualizations.
Upon implementation,we will provide comparisons between K-Means clustering vs Hierarchical
clustering highlighting the strengths and limitations of each approach in the context of your
analysis.

Our findings will help inform the team in formulating the marketing and sales
strategies of the brand.

## 2.Data Sourcing
The dataset consists of 10 numerical and 8 categorical attributes.

#### The ‘Revenue’

attribute can be used as the class label.

#### Types of Pages:Administrative,Informational,Time spent on pages: Admin Duration and Info Duration

“Administrative”, “Administrative Duration”, “Informational”, “Informational Duration”,
“Product Related” and “Product Related Duration” represents the number of different types
of pages visited by the visitor in that session and total time spent in each of these page
categories.

The values of these features are derived from the URL information of the pages visited by
the user and updated in real-time when a user takes an action, e.g. moving from one page to
another.

#### Metrics: Bounce rate, Exit rate and Page Value

The “Bounce Rate”, “Exit Rate” and “Page Value” features represent the metrics measured
by “Google Analytics” for each page in the e-commerce site.

The value of the “Bounce Rate” feature for a web page refers to the percentage of visitors
who enter the site from that page and then leave (“bounce”) without triggering any other
requests to the analytics server during that session.

The value of the “Exit Rate” feature for a specific web page is calculated as for all pageviews
to the page, the percentage that was the last in the session.
The “Page Value” feature represents the average value for a web page that a user visited
before completing an e-commerce transaction.

#### Type of days: Speical or Ordinary
The “Special Day” feature indicates the closeness of the site visiting time to a specific
special day (e.g. Mother’s Day, Valentine’s Day) in which the sessions are more likely to be
finalized with the transaction.
The value of this attribute is determined by considering the dynamics of e-commerce such
as the duration between the order date and delivery date. For example, for Valentina’s day,
this value takes a nonzero value between February 2 and February 12, zero before and
after this date unless it is close to another special day, and its maximum value of 1 on
February 8.

#### Type of visit, Operating system, Browser and region(location)
The dataset also includes the operating system, browser, region, traffic type, visitor type as
returning or new visitor, a Boolean value indicating whether the date of the visit is
weekend, and month of the year.


## 3.Data Exploration

#### We will start by installing our packages and libraries 

```{r}
#install_github("vqv/ggbiplot")
#install.packages("rtools")
#install.packages("DataExplorer")
#install.packages("Hmisc")
#install.packages("pastecs")
#install.packages("psych")
#install.packages("corrplot")
#install.packages("factoextra")
#install.packages("caret")
```


```{r}
#Loading the libraries
#specify the path where the file is located

library("data.table")

#Loading the other libraries
library(devtools)
library(tidyverse)
library(magrittr)
library(warn = -1)
library(ggplot2)
library(lattice)
library(corrplot)
library(DataExplorer)
library(Hmisc)
library(pastecs)
library(psych)
library(factoextra)
library(caret)
```


#### Loading datasets
```{r}
library("readr")
kr <- read.csv("http://bit.ly/EcommerceCustomersDataset")

head(kr)

```

#### Previewing the bottom of the dataset

```{r}
tail(kr)
```

#### checking the datatypes

```{r}
#Provides the structure of the dataset in terms of datatypes
str(kr) 
```
#we can observe 12330 rows and 18 columns
#we can also observe that most columns are num=numbers or int=intergers
# there is boolean type of data in weekend and revenue"false" or "true"
# the month column is the only character column


```{r}
# check dimensions
dim(kr)
```
#confirming the rows and columns above 12330 rows and 18 columns


```{r}
# Lists column names of the dataset
#all columns are abit easy to write though we can make them of the same case and shorter
names(kr) 

```


```{r}
# Number of missing values per column since we have too many rows
colSums(is.na(kr)) 
```
# we can observe that 8 columns have 14 missing values
# we can check the % LATER though it might not affect our analyis


```{r}
#checking on duplicated rows
duplicated_rows <- kr[duplicated(kr),]
dim(duplicated_rows)
```
#we observe that 119 rows in the 18 columns have been duplicated.


## 4.Tidying the dataset

```{r}
#we will first start by making the column names uniform case in our case lower
# First we Change the type of the loaded dataset to a dataframe

kr = as.data.frame(kr)

# Change column names, by making them uniform

colnames(kr) = tolower(colnames(kr))

#to confirm the change

names (kr)
```

Factors are used to represent categorical data. Factors can be ordered or unordered and are an important class for statistical analysis and for plotting.

```{r}
#For the categorical data we change to levels

cat= c('month', 'operatingsystems', 'browser', 'region', 'traffictype', 'visitortype')

# Changing columns to factors
kr[,cat] %<>% lapply(function(x) as.factor(as.character(x)))
str(kr)
```
we can observe that month has 10 levels meaning 10 unique values for the months with 9 different regions and 20 different traffic types  with 8 different operating systems.But we will observe further the different ways customer segment in clustering.


```{r}
#we then go ahead and omit the missing values since the data is from a website
#Dropping  missing values

kr = na.omit(kr)
colSums(is.na(kr))

```

```{r}
#we will still go ahead and drop the duplicated rows
kr <- kr[!duplicated(kr), ]

#confirming the drop
dim(kr)
```
we can observe that our rows reduced from 12133 to 12199.


```{r}
#We can go ahead and check for outliers
#First we select numeric columns
nums <- subset(kr, select = -c(specialday, month, operatingsystems,browser, region, traffictype, visitortype,weekend,revenue))

colnames(nums)

boxplot(nums)

```
we observe that all numeric columns have outliers.But the outliers are expected since our dataframe has customers from very diverse backgrounds and very different lifestyles and spending patterns.


from here we can start indepth analysis of our dataset



## 5.Exploratory Data Analysis
### Univariate Analysis

#### Descriptive analysis around measures of central tendecy
```{r}
#we can only get statistics of numerics
#since we Already have defined it above

describe(nums)
```
* we observe that all columns have a sample size of 12199 just like our rows
* productrelated_duration has the highest mean with lowest being bouncerates
* all our skew values are positive which shows that our dataset is skewed right or right tailed
* our data is asymmetrical since no feature has skeweness near 
* unfortunately all our variables have high kurtosis.
* high kurtosis suggests that dataset has outliers or heavy-tailed
* productrelated_duration have most outliers since it has the highest kurtosis of 136.57
* exitrates and administrative have lowest outliers and kurtosis

** From the above we observe that Product related duration has the largest figures and range, meaning customers visiting the website spend alot of time in the product related
page also they  spend a considerable amount of time checking on the administration and the
least of time checking out the information related page **


#### Histogram
Histogram is effective graphical technique for showing both the skewness and kurtosis AS shown below:
```{r}
str(kr)

```

#### histograms(numerical data)
```{r}
par(mfrow = c(2, 2))
hist(nums$administrative)
hist(nums$informational)
hist(nums$bouncerates)
hist(nums$exitrates)
```

```{r}
par(mfrow = c(2, 2))
hist(nums$administrative_duration)
hist(nums$informational_duration)
hist(nums$productrelated_duration)
hist(nums$pagevalues)
```

From the above distributions we can conclude that 

* .Our numerical values are skewed to the left 
* .They don’t follow a normal distribution 
* .Variables dealing with duration have larger values
* .Exit rates vary alot

### frequency barplots(categorical data)


```{r}
#revenue
r <- ggplot(data =kr) +
geom_bar(mapping = aes(x = revenue))
#weekends or not
w <- ggplot(data = kr) +
geom_bar(mapping = aes(x = weekend))
#type of visitors frequented the website
v <-ggplot(data = kr) +
geom_bar(mapping = aes(x = visitortype))
#traffic type 
t <- ggplot(data = kr) +
geom_bar(mapping = aes(x = traffictype))
ggarrange(r, w, v, t + rremove("x.text"),
ncol = 2, nrow = 2)
```



```{r}
#Which months had the highest traffic
m <- ggplot(data = kr) +
geom_bar(mapping = aes(x = month))
#Distribution of operating systems on traffic
o <- ggplot(data = kr) +
geom_bar(mapping = aes(x = operatingsystems))
#Browser distribution
b <-ggplot(data = kr) +
geom_bar(mapping = aes(x = browser))
#Which regions trafficked the website the most?
r <- ggplot(data = kr) +
geom_bar(mapping = aes(x = region))
ggarrange(m, o, b, r + rremove("x.text"),
ncol = 2, nrow = 2)
```

* Most of the traffic in the website doesn’t generate any revenue 
* There is more traffic on weekdays than weekends, but the traffic on weekends is relatively high considering that weekends consist of only 2 days per week. 
* Most of the people visiting * the website are returning visitors, only a small percentage are new
*There is alot of traffic in the website in May, November, March and Dec 
* Almost 5000 of the traffic in the website for the year was from region 1, around 2,300 from region 3 and the other regions ranging from 1000 to 300 individuals.


### Bivariate Analysis

```{r}
#Revenue trend monthly
kr %>%
ggplot() +
aes(x = month, revenue = ..count../nrow(kr), fill = revenue) +
geom_bar() +
ylab("monthly revenue trends")
```

Revenue was highest in the month of november this is definitely because of the december holidays and also because of black friday sales which mostly happens during this month.


```{r}
#weekend revenue trend
ggplot(kr,
aes(x = revenue,
fill = weekend)) +
geom_bar(position = "stack")
```
There are more revenue generated during the weekday.This means more people are online during the weekdays.


```{r}
#countries revenue trend
kr %>%
ggplot() +
aes(x = region, revenue = ..count../nrow(kr), fill = revenue) +
geom_bar() +
ylab("relative frequency")
```
regions 1 and 3 hAve most revenue collection online.


```{r}
#traffic type trend
kr %>%
ggplot() +
aes(x = traffictype, revenue = ..count../nrow(kr), fill = revenue) +
geom_bar() +
ylab("relative frequency")
```
the highest traffic type is 1 and 2

```{r}
kr %>%
 ggplot(aes(month)) +
 geom_bar(aes(fill = visitortype))+
 labs(title = "Stacked Chart: Visitor Type by Month")
```
most of the frequent customers visit site during month of may with most of the new customers onboarding the site during the month of Nov and Dec.Other class of visitors usually frequent the site on month Of dec,Which makes sense because of the holidays


```{r}

options(repr.plot.width = 11, repr.plot.height = 7)
p1 = ggplot(kr, aes(productrelated, col = revenue)) +
geom_density(aes(fill = revenue), alpha = 0.4) +
labs(x = 'Product related', y = 'Density', title = '') +
theme(legend.position = 'none',
plot.title = element_text(size = 12))

ggarrange(p1 + rremove("x.text"),
ncol = 2, nrow = 2)

```

